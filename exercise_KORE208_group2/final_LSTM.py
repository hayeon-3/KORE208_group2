# -*- coding: utf-8 -*-
"""LSTM_oldkor.ipynb

Automatically generated by Colab.


"""
#%%
#작업경로 확인 -> 실습을 위해 반드시 파일 경로를 수정해주세요.
import os
os.getcwd()
#os.chdir("./exercise_KORE208_group2")

# %%
#필요한 패키지 import
#CSV 파일은 현재 github 내 final_dataframe.csv 불러오시면 됩니다.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

#%%
# 1. CSV 파일 로드
df = pd.read_csv('./final_dataframe.csv')

#%%
# 2. 'content' 열 토큰화 (공백 기반 어절 split)
# Tokenizer는 내부적으로 텍스트를 공백 기준으로 분리하므로, 이 단계에서 직접 split()을 하지 않고
# Tokenizer에 리스트 형태가 아닌 문자열 리스트를 바로 전달하는 것이 더 효율적
# df['tokenized_content'] = df['content'].apply(lambda x: x.split(' '))

#%%
# 3. 어휘 집합 구축 및 정수 인코딩 (keras Tokenizer 활용)
# num_words: 가장 빈도가 높은 단어들만 사용할지 여부 (여기서는 모든 단어 사용)
# oov_token: Out-Of-Vocabulary 단어를 처리할 토큰 (훈련 데이터에 없는 단어)
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df['content']) # 텍스트를 학습하여 어휘 집합 구축

word_index = tokenizer.word_index # 단어-정수 매핑 딕셔너리
vocab_size = len(word_index) + 1 # 어휘 집합 크기 (+1은 0번 패딩 토큰 때문)

print(f"\n어휘 집합 크기 (vocab_size): {vocab_size}")
print("\n단어-정수 매핑 예시 (상위 10개):")
# sorted(word_index.items(), key=lambda item: item[1])은 값(정수 인덱스) 기준으로 정렬
for word, index in list(word_index.items())[:10]:
    print(f"'{word}': {index}")

# 텍스트 시퀀스를 정수 시퀀스로 변환
encoded_sequences = tokenizer.texts_to_sequences(df['content'])

print("\n정수 인코딩된 시퀀스 예시 (첫 2개):")
for i, seq in enumerate(encoded_sequences[:2]):
    print(f"Original: '{df['content'].iloc[i]}'")
    print(f"Encoded: {seq}\n")

#%%
#encoded_sequences 리스트의 각 시퀀스 길이 확인인
lengths = [len(s) for s in encoded_sequences]

plt.hist(lengths, bins=50) # 길이에 따라 50개의 구간으로 히스토그램 생성
plt.title('Distribution of Sequence Lengths')
plt.xlabel('Sequence Length')
plt.ylabel('Number of Sequences')
plt.show()

# 통계 정보 확인 (평균, 중간값, 90% 지점)
print(f"평균 시퀀스 길이: {np.mean(lengths):.2f}")
print(f"중간 시퀀스 길이: {np.median(lengths)}")
print(f"90% 지점 시퀀스 길이: {np.quantile(lengths, 0.90)}")
print(f"최대 시퀀스 길이 (원본): {max(lengths)}")

#%%
# 4. 패딩 (Padding)
# 딥러닝을 위해 모든 시퀀스의 길이를 동일하게 맞추는 과정
# 평균 시퀀스가 매우 긴 현재 데이터 특성상, 메모리 용량에 맞춰 최대 시퀀스로 패딩
# 보통 자연어 처리에서 2048을 max값으로 사용한다고 하나, 중간값인 6052까지 높여서 학습 진행함 
max_sequence_length = 6052
print(f"\n최대 시퀀스 길이: {max_sequence_length}")

padded_sequences = pad_sequences(encoded_sequences, maxlen=max_sequence_length, padding='post') 

print("\n패딩된 시퀀스 예시 (첫 2개):")
print(padded_sequences[:2])

#%%
# 5. 타임라인 레이블 정수 인코딩
# 현재 4개의 레이블: '15C', '16C', 'modern', 'enlightenmen'
# 딥러닝 분류 모델의 출력 레이어에 One-Hot Encoding을 사용
# 자동 지정시 알파벳 순이 Default이므로, 가독성을 위해 직접 시기순으로 지정 

desired_timeline_order = ['15C', '16C', 'modern', 'enlightenment']

df['timeline_encoded'] = pd.Categorical(df['timeline'], categories = desired_timeline_order, ordered = True)
num_classes = len(desired_timeline_order) # 분류할 클래스 개수

print(f"\n타임라인 레이블 및 인코딩:")
for i, label in enumerate(desired_timeline_order):
    print(f"'{label}' -> {i}")
print(f"총 분류 클래스 수: {num_classes}")
print("\n인코딩된 타임라인 레이블 예시:")
print(df[['timeline', 'timeline_encoded']].head())

# 모델 입력 준비 완료:
# X: padded_sequences 
# y: df['timeline_encoded'].values 

# %%
# 6. 타임라인 레이블 원-핫 인코딩
# 딥러닝 분류 모델의 출력 레이어에 사용될 원-핫 인코딩
# 예: 0 -> [1, 0, 0], 1 -> [0, 1, 0], 2 -> [0, 0, 1]

labels_one_hot = pd.get_dummies(df['timeline_encoded'])

print(f"\n원-핫 인코딩된 타임라인 레이블 예시 (순서 지정):")
print(labels_one_hot[:5])

#%%
# 7. 데이터 분할 (훈련, 테스트 세트)
# 모델 훈련을 위한 입력(X)과 정답(y) 데이터 준비
X = padded_sequences # 패딩된 정수 시퀀스 (모델 입력)
y = labels_one_hot # 원-핫 인코딩된 타임라인 레이블 (모델 정답)

# 데이터를 훈련 세트와 테스트 세트로 분할
# test_size=0.2: 전체 데이터의 20%를 테스트 데이터로 사용
# random_state=42: 재현성을 위한 시드 (동일한 결과를 얻기 위해 고정)
# stratify=y: y(레이블)의 비율을 훈련/테스트 세트에서 동일하게 유지 (클래스 불균형 방지)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\n훈련 데이터 X_train shape: {X_train.shape}")
print(f"훈련 데이터 y_train shape: {y_train.shape}")
print(f"테스트 데이터 X_test shape: {X_test.shape}")
print(f"테스트 데이터 y_test shape: {y_test.shape}")

#%%
# 8. LSTM 모델 정의 및 구축

embedding_dim = 100 # 각 단어(어절)를 표현할 임베딩 벡터의 차원 (하이퍼파라미터, 50~300 사이에서 조절)

model = Sequential() # 순차적으로 레이어를 쌓아 올리는 Keras 모델
# Embedding Layer: 단어 인덱스를 저차원 밀집 벡터(임베딩)로 변환하는 역할
# input_dim: 어휘 집합의 크기 (총 단어 개수, vocab_size, 이전 코드에서 계산됨)
# output_dim: 임베딩 벡터의 차원 (embedding_dim)
# input_length: 입력 시퀀스의 길이 (패딩된 최대 길이, max_sequence_length, 이전 코드에서 계산됨)
model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))

# LSTM Layer: 시퀀스 데이터를 처리하고 장기 의존성을 학습
# units: LSTM 셀의 출력 차원 (hidden state size), 모델의 '기억력'과 복잡도를 결정 (하이퍼파라미터, 64, 128, 256 등)
# return_sequences=False: 분류 작업이므로 마지막 타임 스텝의 출력만 Dense Layer로 전달
model.add(LSTM(units=128))

# Dropout Layer: 과적합(overfitting) 방지를 위해 무작위로 일부 뉴런을 비활성화
# 0.5: 50%의 뉴런을 비활성화 (하이퍼파라미터, 0.2~0.5 사이에서 조절)
model.add(Dropout(0.5))

# Dense Layer (출력 층): 최종 분류를 위한 완전 연결층
# units: 분류할 클래스의 개수 (num_classes, 이전 코드에서 계산됨)와 동일해야 함
# activation='softmax': 다중 클래스 분류 시 각 클래스에 속할 확률을 출력
model.add(Dense(units=num_classes, activation='softmax'))

# 모델의 구조 요약 정보 출력
model.summary()

#%%
# 9. 모델 컴파일
# 모델 학습에 필요한 설정 (최적화 방법, 손실 함수, 평가 지표)
model.compile(
    optimizer='adam', # 최적화 도구: Adam (가장 널리 사용되고 효과적)
    loss='categorical_crossentropy', # 손실 함수: 다중 클래스 분류를 위한 교차 엔트로피 (원-핫 인코딩된 레이블 사용 시)
    metrics=['accuracy'] # 모델 성능 평가 지표: 정확도
)

#%%
# 10. 모델 학습 (훈련)
# EarlyStopping 콜백 정의
# monitor='val_accuracy': 검증 정확도를 모니터링
# patience=10: 검증 정확도가 10 에포크 동안 개선되지 않으면 훈련 중단
# min_delta=0.0: 어떠한 변화라도 감지하도록 함 
# restore_best_weights=True: 훈련 중 가장 좋았던 가중치로 모델을 복원
early_stopping_callback = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    min_delta=0.0,
    restore_best_weights=True,
    verbose=1 # Early Stopping 작동 시 메시지 출력하도록 함
)
print("EarlyStopping 콜백 정의 완료.")

# X_train과 y_train 데이터를 사용하여 모델 학습
# validation_split을 사용하여 훈련 데이터 중 일부를 검증 데이터로 사용
# EarlyStopping은 이 validation_split으로 나뉜 검증 데이터의 성능을 모니터
history = model.fit(
    X_train, y_train,
    epochs=100, # 에포크가 충분히 커도, early stopping이 알아서 멈춰줄 것임
    batch_size=16,
    validation_split=0.2, # 훈련 데이터 중 20%를 검증 데이터로 사용
    callbacks=[early_stopping_callback],
    verbose=1
)
print("\n모델 학습 완료 (Early Stopping 적용).")

#%%
# 11. 모델 평가 (테스트 데이터)
# 훈련되지 않은 X_test와 y_test 데이터를 사용하여 최종 모델 성능 평가
loss, accuracy = model.evaluate(X_test, y_test, verbose=0) # verbose=0: 출력 없이 결과만 반환
print(f"\n테스트 데이터 손실(Loss): {loss:.4f}")
print(f"테스트 데이터 정확도(Accuracy): {accuracy:.4f}")

#%%
# 12. 추가: 학습 과정 시각화 
# 학습 히스토리에서 정확도와 손실값 가져오기
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

#%%
# 13. 추가: 예측 및 분류 결과 확인
# 테스트 데이터의 일부 샘플에 대한 예측
predictions = model.predict(X_test)
# 각 예측은 클래스별 확률 분포이므로, 가장 높은 확률을 가진 클래스를 선택
predicted_classes = np.argmax(predictions, axis=1)

# 실제 클래스와 예측 클래스를 비교
true_classes = np.argmax(y_test, axis=1)

print("\n--- 테스트 데이터 예측 결과 예시 ---")
for i in range(min(5, len(X_test))): # 첫 5개 샘플만 확인
    print(f"샘플 {i+1}:")
    print(f"  실제 레이블 (인코딩): {true_classes[i]}")
    print(f"  예측 레이블 (인코딩): {predicted_classes[i]}")
    # 실제 레이블을 원래 문자열로 변환 (역변환)
    print(f"  실제 시대: {desired_timeline_order[true_classes[i]]}")
    print(f"  예측 시대: {desired_timeline_order[predicted_classes[i]]}")
    print("-" * 20)
# %%
# 14. 추가: Confusion Matrix로 test set accuracy 시각화

y_true = np.argmax(y_test, axis=1)
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)

display_labels = desired_timeline_order

CM = confusion_matrix(y_true, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=CM, display_labels=display_labels)

# cmap은 색상 맵 (Blues는 파란색 계열, 값이 클수록 진해짐)
# values_format='d'는 각 셀의 값을 정수형으로 표시
disp.plot(cmap='Blues', values_format='d')

plt.title('Confusion Matrix', fontsize=16)
plt.xlabel('Predicted timeline', fontsize=14)
plt.ylabel('True timeline', fontsize=14)

plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)

plt.tight_layout()
plt.show()
# %%
